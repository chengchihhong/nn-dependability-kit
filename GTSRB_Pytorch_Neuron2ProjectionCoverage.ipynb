{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuron 2-projection on-off activation coverage (2) - German Traffic Sign Recognition Benchmark (GTSRB)\n",
    "\n",
    "For detailed explanation, please refer to the jupyter notebook 1_MNIST_Pytorch_CNN.ipydb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random\n",
    "# Fix the number for repeatability (we have also stored the trained model)\n",
    "numpy.random.seed(42)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by accessing the root folder where internally, subfolders are images with folder name being their classified result.\n",
    "\n",
    "The dataset should be available at the following site \n",
    "http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset\n",
    "\n",
    "Here we just pick the 26K smaller training set (the online version), as the training and test set can all be directly loaded using PyTorch included functionalities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "standard_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # Change the image to PIL format, such that resize can be done\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((32,32)),\n",
    "        # Bring it back to tensor\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "# Here the data is not be normalized to [-1,1]\n",
    "\n",
    "# Change the folder based on your specific needs. \n",
    "# This one is a smaller (26640 examples) data set (for online training), so the \n",
    "data = ImageFolder(root='data/GTSRB-Training_fixed/GTSRB/Training',  transform=standard_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0 \t Speed limit (20km/h)\n",
    "- 1 \t Speed limit (30km/h)\n",
    "- 2 \t Speed limit (50km/h)\n",
    "- 3 \t Speed limit (60km/h)\n",
    "- 4 \t Speed limit (70km/h)\n",
    "- 5 \t Speed limit (80km/h)\n",
    "- 6 \t End of speed limit (80km/h)\n",
    "- 7 \t Speed limit (100km/h)\n",
    "- 8 \t Speed limit (120km/h)\n",
    "- 9 \t No passing\n",
    "- 10 \t No passing for vechiles over 3.5 metric tons\n",
    "- 11 \t Right-of-way at the next intersection\n",
    "- 12 \t Priority road\n",
    "- 13 \t Yield\n",
    "- 14 \t Stop\n",
    "- 15 \t No vechiles\n",
    "- 16 \t Vechiles over 3.5 metric tons prohibited\n",
    "- 17 \t No entry\n",
    "- 18 \t General caution\n",
    "- 19 \t Dangerous curve to the left\n",
    "- 20 \t Dangerous curve to the right\n",
    "- 21 Double curve\n",
    "- 22 \t Bumpy road\n",
    "- 23 \t Slippery road\n",
    "- 24 \t Road narrows on the right\n",
    "- 25 \t Road work\n",
    "- 26 \t Traffic signals\n",
    "- 27 \t Pedestrians\n",
    "- 28 \t Children crossing\n",
    "- 29 \t Bicycles crossing\n",
    "- 30 \t Beware of ice/snow\n",
    "- 31 \t Wild animals crossing\n",
    "- 32 \t End of all speed and passing limits\n",
    "- 33 \t Turn right ahead\n",
    "- 34 \t Turn left ahead\n",
    "- 35 \t Ahead only\n",
    "- 36 \t Go straight or right\n",
    "- 37 \t Go straight or left\n",
    "- 38 \t Keep right\n",
    "- 39 \t Keep left\n",
    "- 40 \t Roundabout mandatory\n",
    "- 41 \t End of no passing\n",
    "- 42 \t End of no passing by vechiles over 3.5 metric tons\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "num_classes = 43\n",
    "learning_rate = 0.001\n",
    "sizeOfNeuronsToMonitor = 84\n",
    "batch_size = 64\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import util\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print(images.shape)\n",
    "util.displayGTSRB(images[0].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 40, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(40)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(40, 20, 5)\n",
    "        self.conv2_bn = nn.BatchNorm2d(20)\n",
    "        self.fc1 = nn.Linear(20 * 5 * 5, 240)        \n",
    "        self.fc2 = nn.Linear(240, sizeOfNeuronsToMonitor)\n",
    "        self.fc3 = nn.Linear(sizeOfNeuronsToMonitor, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.conv2_bn((self.conv2(x)))))\n",
    "        # Flatten it to an array of inputs\n",
    "        x = x.view(-1, 20 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x \n",
    "\n",
    "    def forwardWithIntermediate(self, x):\n",
    "        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.conv2_bn((self.conv2(x)))))\n",
    "        # Flatten it to an array of inputs\n",
    "        x = x.view(-1, 20 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        intermediateValues = F.relu(self.fc2(x))\n",
    "        x = self.fc3(intermediateValues)\n",
    "        return x , intermediateValues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. to load pre-trained model:\n",
    "net.load_state_dict(torch.load('models/3_model_GTSRB_CNN_27k_train99%.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)  \n",
    "\n",
    "furtherTrain = False\n",
    "\n",
    "if furtherTrain: \n",
    "\n",
    "    # Train the model\n",
    "    total_step = len(loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loader):  \n",
    "            # Move tensors to the configured device\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing, we should also use the test data, where they are separated into folders based on their classes, followed by shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "testdata = ImageFolder(root='data/GTSRB_Online-Test-Images-Sorted/GTSRB/Online-Test-sort', transform=standard_transform)\n",
    "testloader = DataLoader(testdata, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "util.displayGTSRB(images[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print(predicted)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(num_classes))\n",
    "class_total = list(0. for i in range(num_classes))\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels)\n",
    "        label = labels[0]\n",
    "        class_correct[label] += c[0].item()\n",
    "        class_total[label] += 1\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network over test images: {} %\\n\\n'.format(100 * correct / total))\n",
    "\n",
    "for i in range(num_classes):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        i, 100 * class_correct[i] / class_total[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network over train images: {} %\\n\\n'.format(100 * correct / total))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger 2-projection neuron on-off activation coverage computation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nndependability.metrics import KProjection\n",
    "\n",
    "k_Value = 2\n",
    "\n",
    "metric = KProjection.Neuron_OnOff_KProjection_Metric(k_Value, sizeOfNeuronsToMonitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigger the function addInputs() to update the k-projection table based on all visited patterns for each batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    total = 0\n",
    "    i = 0\n",
    "    for images, labels in loader:\n",
    "        \n",
    "        total = total + (len(labels))\n",
    "        labels = labels.to(device)\n",
    "        outputs, intermediateValues = net.forwardWithIntermediate(images)\n",
    "        \n",
    "        # Add the batch of neuron activation patterns to the k-projection table\n",
    "        metric.addInputs(intermediateValues.numpy())\n",
    "                \n",
    "        if(i % 50) == 0:\n",
    "            print('Current input size fed into the metric: '+str(total))\n",
    "            metric.printMetricQuantity()\n",
    "            print(\"\\n\")\n",
    "        i = i+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.printMetricQuantity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Now, ask the test case generator to derive us a pattern which maximally increases 2-projection coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nndependability.atg.nap import napgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "napgen.proposeNAPcandidate(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
